wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
/home/home01/sclaam/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.
  f"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will "
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type                       | Params
-----------------------------------------------------------
0 | model       | WideResNet                 | 1.1 M
1 | loss_object | LabelSmoothingCrossEntropy | 0
-----------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.319     Total estimated model params size (MB)
/home/home01/sclaam/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.

Epoch 0:   0%|          | 0/356 [00:00<?, ?it/s]
/home/home01/sclaam/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:231: UserWarning: You called `self.log('Train FLOPS', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.















Epoch 0:  99%|█████████▉| 352/356 [00:32<00:00, 10.79it/s, v_num=5n0l]
















Epoch 1:  99%|█████████▉| 352/356 [01:06<00:00,  5.26it/s, v_num=5n0l, val_loss=2.210, top1_acc=0.195, top5_acc=0.709]


































Epoch 3:  99%|█████████▉| 352/356 [02:16<00:01,  2.57it/s, v_num=5n0l, val_loss=1.940, top1_acc=0.266, top5_acc=0.879]





















































Epoch 6:  99%|█████████▉| 352/356 [04:06<00:02,  1.43it/s, v_num=5n0l, val_loss=1.970, top1_acc=0.303, top5_acc=0.828]

















Epoch 7:  99%|█████████▉| 352/356 [04:42<00:03,  1.25it/s, v_num=5n0l, val_loss=1.990, top1_acc=0.277, top5_acc=0.836]

















Epoch 8:  99%|█████████▉| 352/356 [05:18<00:03,  1.11it/s, v_num=5n0l, val_loss=1.990, top1_acc=0.295, top5_acc=0.818]


















Epoch 9:  99%|█████████▉| 352/356 [05:55<00:04,  1.01s/it, v_num=5n0l, val_loss=2.000, top1_acc=0.316, top5_acc=0.820]

Files already downloaded and verified
Files already downloaded and verified
Testing: 0it [00:00, ?it/s]

Testing DataLoader 0: 100%|██████████| 79/79 [00:03<00:00, 19.93it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        top1_acc            0.3100000023841858
        top5_acc            0.8334000110626221
        val_loss             1.979060173034668
