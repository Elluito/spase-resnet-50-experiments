wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.9.6
    code_path: code/popen_loky_posix.py
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.5
benchmark:
  desc: null
  value: false
ckpt_dir:
  desc: null
  value: ckpts
ckpt_interval:
  desc: null
  value: 50
dataset:
  desc: null
  value:
    batch_size: 128
    max_threads: 3
    name: CIFAR10
    root: /srv/home/varunsundar/rethinking-sparse-learning/datasets/CIFAR10/
    test_batch_size: 128
    validation_split: 0.1
device:
  desc: null
  value: cuda
exp_name:
  desc: null
  value: Pruning_improved_pruning
log_interval:
  desc: null
  value: 100
masking:
  desc: null
  value:
    apply_when: step_end
    decay_schedule: magnitude-prune
    dense: false
    dense_gradients: true
    density: 1.0
    end_when: 65918
    final_density: 0.05
    growth_mode: none
    interval: 100
    name: Pruning
    prune_mode: global-magnitude
    prune_rate: 0.5
    redistribution_mode: none
    sparse_init: random
    start_when: 700
mixed_precision:
  desc: null
  value: false
model:
  desc: null
  value: wrn-22-2
optimizer:
  desc: null
  value:
    decay_factor: 0.2
    decay_frequency: 30000
    epochs: 250
    lr: 0.1
    momentum: 0.9
    name: SGD
    training_multiplier: 1
    use_nesterov: true
    weight_decay: 0.0005
resume:
  desc: null
  value: true
save_features:
  desc: null
  value: false
seed:
  desc: null
  value: 2
use_wandb:
  desc: null
  value: true
wandb_api_key:
  desc: null
  value: /srv/home/varunsundar/rethinking-sparse-learning/wandb_api.key
